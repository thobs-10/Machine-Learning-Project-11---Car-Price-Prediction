{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid # generates globally unique id's numbers\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from prefect import task, flow\n",
    "#from ...Development_Step.feature_engineering import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"e4761ba7b84842c9b8d224b9ab3aa234\"\n",
    "\n",
    "output_file = f'output/bacth-results.parquet'\n",
    "df = pd.read_csv('C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Machine Learning Project 11 - Car Price Prediction\\\\dataset\\\\eda_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuids(n):\n",
    "    car_ids = []\n",
    "    for i in range(n):\n",
    "        car_ids.append(str(uuid.uuid4()))\n",
    "    return car_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mileage'] = df['kms_driven'].str.split(' ').str[0]\n",
    "df.drop(columns='kms_driven',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def read_dataset(filename:str):\n",
    "    df = pd.read_csv(filename)\n",
    "    # remove the unnamed column\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "    # before making any changes lets copy the  data and work with the copy\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # change the ask for price text value in price column and replace it with 0\n",
    "    #df_copy['Price'] = df_copy['Price'].replace('Ask For Price', 0)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_price_datatype(df_copy):\n",
    "    for i in range(len(df_copy)):\n",
    "        cur_price = df_copy.loc[i,'Price']\n",
    "        if(cur_price!= 0):\n",
    "            cur_price = float(cur_price.replace(',',''))\n",
    "            df_copy.loc[i,'Price']=cur_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the mileage column\n",
    "def fix_mileage_datatype(df_copy):\n",
    "    for i in range(len(df_copy)):\n",
    "        cur_price = df_copy.loc[i,'Mileage']\n",
    "        if(cur_price!=0):\n",
    "            cur_price = float(cur_price.replace(',',''))\n",
    "            df_copy.loc[i,'Mileage']=cur_price\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datatypes(df_copy):\n",
    "    # make the price column to be aa float\n",
    "    df_copy['Price'] = df_copy['Price'].astype(float)\n",
    "    df_copy['Mileage'] = df_copy['Mileage'].astype(float)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with the NAN\n",
    "def fixing_nans(df_copy):\n",
    "    imputer = SimpleImputer(missing_values=0, strategy='mean')\n",
    "    imputer.fit(df_copy.iloc[:, 3:4])\n",
    "    df_copy.iloc[:, 3:4] = imputer.transform(df_copy.iloc[:, 3:4])\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# removee the outliers\n",
    "def remove_year_outliers(df):\n",
    "    # calculate the Quantiles(Q1 and Q3)\n",
    "    Q1 = df['year'].quantile(0.25)\n",
    "    Q3 = df['year'].quantile(0.75)\n",
    "    # calclulate the Inter_quatile_range IQR\n",
    "    IQR = Q3 - Q1\n",
    "    # calculate the lower limit and upper  limit (LL & UL)\n",
    "    LL = Q1 - 1.5 * IQR\n",
    "    UL = Q3 + 1.5 * IQR\n",
    "    # now filter the column to remove the outliers\n",
    "    # replace all the values that are less or equal to the LL in the hours per weeek column with the LL\n",
    "    df.loc[df['year'] <= LL, 'year'] = LL\n",
    "    # do the same for values greater than the UL\n",
    "    df.loc[df['year'] >= UL, 'year'] = UL\n",
    "    return df\n",
    "\n",
    "\n",
    "# removee the outliers\n",
    "def remove_mileage_outliers(df):\n",
    "    # calculate the Quantiles(Q1 and Q3)\n",
    "    Q1 = df['Mileage'].quantile(0.25)\n",
    "    Q3 = df['Mileage'].quantile(0.75)\n",
    "    # calclulate the Inter_quatile_range IQR\n",
    "    IQR = Q3 - Q1\n",
    "    # calculate the lower limit and upper  limit (LL & UL)\n",
    "    LL = Q1 - 1.5 * IQR\n",
    "    UL = Q3 + 1.5 * IQR\n",
    "    # now filter the column to remove the outliers\n",
    "    # replace all the values that are less or equal to the LL in the hours per weeek column with the LL\n",
    "    df.loc[df['Mileage'] <= LL, 'Mileage'] = LL\n",
    "    # do the same for values greater than the UL\n",
    "    df.loc[df['Mileage'] >= UL, 'Mileage'] = UL\n",
    "    return df\n",
    "\n",
    "# seperate the dependant and independent features\n",
    "def seperate_dataset(df_copy):\n",
    "    # drop the unimportant features\n",
    "    df_target = pd.DataFrame()\n",
    "    df_target['Price']=df_copy['Price']\n",
    "    df_copy.drop(['fuel_type'], axis=1, inplace=True)\n",
    "    X = df_copy.drop('Price',axis =1)\n",
    "    #y = df_copy['Price']\n",
    "    return X, df_target\n",
    "# feature engineer the categorical features\n",
    "def feature_engineering(df):\n",
    "    # the code says, for each unique value in column race, find the unique value and associate it with the unique key between(0, 1, 2,...)\n",
    "    # and place that in label encoder race as a dictionary\n",
    "    #df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    label_encoding_name = {value: key for key, value in enumerate(df['name'].unique())}\n",
    "    df['name'] = df['name'].map(label_encoding_name)\n",
    "\n",
    "    label_encoding_company = {value: key for key, value in enumerate(df['company'].unique())}\n",
    "    df['company'] = df['company'].map(label_encoding_company)    \n",
    "    return df\n",
    "\n",
    "# standardization\n",
    "def feature_scaling(features):\n",
    "    # get the standard scaler that was used in training\n",
    "    # load the scaaler\n",
    "    # generate unique id's for the prices\n",
    "    features['car_ids'] = generate_uuids(len(features))\n",
    "    sc = None\n",
    "    scaler_path = os.path.join('C:/Users/Cash Crusaders/Desktop/My Portfolio/Projects/Data Science Projects/Machine Learning Project 11 - Car Price Prediction/dataset/',\n",
    "    'standard_scaler.pkl')\n",
    "    with open(scaler_path, 'rb') as scaler_file:\n",
    "        sc = pickle.load(scaler_file)\n",
    "    scaled_features = sc.transform(features)\n",
    "    return scaled_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(run_id):\n",
    "    logged_model = f'http://127.0.0.1:5000/#/experiments/5/runs/{RUN_ID}/artifacts/model'\n",
    "    model = mlflow.pyfunc.load_model(logged_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model, features, df_target):\n",
    "    # apply the model for prediction and combine the results with the old one in a single dataframe\n",
    "    x = np.array(features).reshape(1, -1)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = features['ride_id']\n",
    "    df_result['actual_price'] = df_target['Price']\n",
    "    df_result['predicted_price'] = y_pred\n",
    "    df_result['diff'] = df_result['actual_price'] - df_result['predicted_price']\n",
    "    df_result['model_version'] = RUN_ID\n",
    "    df_result.to_parquet(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow\n",
    "def main_flow(filename = \"C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Machine Learning Project 11 - Car Price Prediction\\\\dataset\\\\eda_dataset.csv\"):\n",
    "    # read dataset\n",
    "    df_copy = read_dataset(filename)\n",
    "    print(\"Done reading...\")\n",
    "    #apply function\n",
    "    df_copy = fix_price_datatype(df_copy)\n",
    "    print(\"Done fixing price datatypes...\")\n",
    "    #apply function\n",
    "    df_copy = fix_mileage_datatype(df_copy)\n",
    "    print(\"Done fixing mileage datatypes...\")\n",
    "    # change price and mileage to float and int\n",
    "    df_copy = fix_datatypes(df_copy)\n",
    "    print(\"Done fixing datatypes to floats...\")\n",
    "    #apply the function\n",
    "    df_copy = fixing_nans(df_copy)\n",
    "    # remove outliers\n",
    "    df_copy = remove_year_outliers(df_copy)\n",
    "    df_copy = remove_mileage_outliers(df_copy)\n",
    "    # apply function\n",
    "    X, df_target = seperate_dataset(df_copy)\n",
    "    # feature engineer categorical features\n",
    "    prepared_features = feature_engineering(X)\n",
    "    # scale the features\n",
    "    scaled_features= feature_scaling(prepared_features)\n",
    "    # get the model\n",
    "    ml_model = load_model(RUN_ID)\n",
    "    #prediction and conceantenation of the datadframe\n",
    "    apply_model(ml_model, scaled_features, df_target)\n",
    "    # save the correct dataframe\n",
    "    #df_copy.to_csv('C:\\\\Users\\\\Cash Crusaders\\\\Desktop\\\\My Portfolio\\\\Projects\\\\Data Science Projects\\\\Machine Learning Project 11 - Car Price Prediction\\\\dataset\\\\preprocessed_dataset.csv')\n",
    "    #send data to Feature Enginneering\n",
    "    #orchest.output((df_copy, X, y),name='preprocessed-df')\n",
    "\n",
    "#main_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "    main_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74b13156ee32336a91ae017c98b438a6fd9992b5a099c169a831fe64b85fc3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
